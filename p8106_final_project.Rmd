---
title: 'P8106 Final Project: Predicting COVID-19 Recovery Time and Identifying Significant Risk Factors'
author: "Runze Cui (rc3521), Yuchen Hua (yh3555), Hongpu Min (hm2946)"
date: "2023-05-01"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
editor_options: 
  chunk_output_type: console
  header-includes:
   -\usepackage{fancyhdr}
   -\usepackage{lipsum}
   -\pagestyle{fancy}
   -\fancyhead[R]{\thepage}
   -\fancypagestyle{plain}{\pagestyle{fancy}}
--- 

\newpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, message = FALSE, warning = FALSE, dpi = 300, fig.width = 7)
```

```{r package, include=F}
library(tidyverse)
library(ggplot2)
library(caret)
library(mgcv)
library(earth)
library(AppliedPredictiveModeling)
library(vip)
library(patchwork)
library(rpart.plot)
library(rpart)
library(ranger)
library(gbm)
library(parallel)
library(doParallel)
library(pROC)
library(ranger)
library(pdp)
```


# Background

[Check the report]

# Data: 

[Description check the report]

```{r}
# For primary analysis: 
# Dataset Loading:
load("data/recovery.Rdata")

set.seed(3521) # Runze Cui's uni(2183): 
# Create a first random sample of 2000 participants: 
dat1 <- dat[sample(1:10000, 2000),] 

set.seed(3555) # Yuchen Hua's uni(3555)
# Create a second random sample of 2000 participants: 
dat2 <- dat[sample(1:10000, 2000),] 

# Merged the two datasets and remove repeated observations: 
dat <- unique(rbind(dat1, dat2))

# Get rid of the id variable from the merged dataset and do the data cleaning: 
dat <- dat %>% 
  select(-id) %>% 
  mutate(gender = as.factor(gender)) %>% 
  mutate(race = as.factor(race)) %>% 
  mutate(smoking = as.factor(smoking)) %>% 
  mutate(hypertension = as.factor(hypertension)) %>% 
  mutate(diabetes = as.factor(diabetes)) %>% 
  mutate(vaccine = as.factor(vaccine)) %>% 
  mutate(severity = as.factor(severity)) %>% 
  mutate(study = as.factor(study)) %>% 
  na.omit() %>% 
  relocate(recovery_time)

head(dat)

# Separate the data as training and test data: 
set.seed(3521)
# Specify rows of training data: 
trRows <- createDataPartition(dat$recovery_time, p = 0.7, list = FALSE)


# Training data:
training <- dat[trRows, ]
## Covariates' matrix:
x <- model.matrix(recovery_time ~ ., dat)[trRows, -1]
## Response's vector:
y <- dat$recovery_time[trRows]

# Test data:
test <- dat[-trRows, ]
## Covariates' matrix:
x2 <- model.matrix(recovery_time ~ ., dat)[-trRows, -1]
## Response's vector:
y2 <- dat$recovery_time[-trRows]




# For secondary analysis: 
dat_2 <- dat %>%
  mutate(recovery_time = ifelse(recovery_time > 30, "great", "less")) %>%
  mutate(recovery_time = as.factor(recovery_time))

# Training data:
training_sec <- dat_2[trRows, ]
## Covariates' matrix:
x_sec <- model.matrix(recovery_time ~ ., dat_2)[trRows, -1]
## Response's vector:
y_sec <- dat_2$recovery_time[trRows]

# Test data:
test_sec <- dat_2[-trRows, ]
## Covariates' matrix:
x2_sec <- model.matrix(recovery_time ~ ., dat_2)[-trRows, -1]
## Response's vector:
y2_sec <- dat_2$recovery_time[-trRows]
```



# Exploratory Analysis and Data Visualization

[Description check the report] 

## Exploratory Analysis

```{r}
# Summary tables separated by continuous/categorical variables:
skimr::skim(dat)
skimr::skim(dat_2)
```

## Data Visualization

```{r}
# For primary analysis: 
## For continuous variables: 
theme = trellis.par.get()
theme$plot.symbol$col = rgb(.2, .4, .2, .5)
theme$plot.symbol$pch = 16
theme$plot.line$col = rgb(.8, .1, .1, 1)
theme$plot.line$lwd = 2
theme$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme)

featurePlot(x = dat %>% dplyr::select(age, height, weight, bmi, SBP, LDL), 
            y = dat$recovery_time,
            plot = "scatter",
            span = .5,
            labels = c("Predictors","Y"),
            main = "Figure 1.1. Lattice Plots for Continuous Variables in Primary Analysis",
            type = c("p", "smooth"))

## For categorical variables: 
gender_plot = dat %>%
  ggplot(aes(x = gender, y = recovery_time, fill = gender)) + 
  geom_violin(color = "black", alpha = .5) + 
  scale_x_discrete(labels = c('Female','Male')) +
  ylab("Recovery") +
  theme(legend.position = "none")

race_plot = dat %>%
  ggplot(aes(x = race, y = recovery_time, fill = race)) + 
  geom_violin(color = "black", alpha = .5) + 
  scale_x_discrete(labels = c('White','Asian','Black', 'Hispanic')) +
  ylab("Recovery") +
  theme(legend.position = "none")

smoking_plot = dat %>%
  ggplot(aes(x = smoking, y = recovery_time, fill = smoking)) + 
  geom_violin(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('Never smoked','Former smoker','Current smoker')) +
  ylab("Recovery") +
  theme(legend.position = "none")

hyper_plot = dat %>%
  ggplot(aes(x = hypertension, y = recovery_time, fill = hypertension)) + 
  geom_violin(color = "black", alpha = .5) +
  ylab("Recovery") +
  scale_x_discrete(labels = c('No','Yes')) +
  theme(legend.position = "none")

diabetes_plot = dat %>%
  ggplot(aes(x = diabetes, y = recovery_time, fill = diabetes)) + 
  geom_violin(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('No','Yes')) +
  ylab("Recovery") +
  theme(legend.position = "none")

vac_plot = dat %>%
  ggplot(aes(x = vaccine, y = recovery_time, fill = vaccine)) + 
  geom_violin(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('Not vaccinated','Vaccinated')) +
  ylab("Recovery") +
  theme(legend.position = "none")

severity_plot = dat %>%
  ggplot(aes(x = severity, y = recovery_time, fill = severity)) + 
  geom_violin(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('Not severe','Severe')) + 
  ylab("Recovery") +
  theme(legend.position = "none")

study_plot = dat %>%
  ggplot(aes(x = study, y = recovery_time, fill = study)) + 
  geom_violin(color = "black", alpha = .5) +
  ylab("Recovery") +
  theme(legend.position = "none")

(gender_plot + race_plot + smoking_plot + hyper_plot) / (diabetes_plot + vac_plot + severity_plot + study_plot) + 
  plot_layout(guides = "collect") + 
  plot_annotation(title = "Figure 1.2. Violin Plots for Categorical Variables in Primary Analysis")

## Correlation matrix for continuous variables ONLY: 
model.matrix( ~ 0+., data = dat %>% dplyr::select(age, height, weight, bmi, SBP, LDL)) %>% 
  cor(use = "pairwise.complete.obs") %>% 
  ggcorrplot::ggcorrplot(show.diag = T, 
                         type = "lower", 
                         lab = F,
                         colors = c("#6D9EC1", "white", "#E46726")) + 
  ggtitle("Figure 1.3. Correlation matrix for continuous datasat")


# For secondary analysis: 
## For continuous variables: 
theme = trellis.par.get()
theme$plot.symbol$col = rgb(.2, .4, .2, .5)
theme$plot.symbol$pch = 16
theme$plot.line$col = rgb(.8, .1, .1, 1)
theme$plot.line$lwd = 2
theme$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme)

featurePlot(x = dat_2 %>% dplyr::select(age, height, weight, bmi, SBP, LDL), 
            y = dat_2$recovery_time,
            plot = "box", pch = "|", 
            scales = list(x = list(relation = "free"),
                          y = list(relation = "free")),
            labels = c("Predictors","Y"),
            main = "Figure 1.4. Lattice Plots for Continuous Variables in Secondary Analysis", 
            auto.key = list(columns = 2))

## For categorical variables: 
gender_plot_sec = dat_2 %>%
  ggplot(aes(x = gender, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) + 
  scale_x_discrete(labels = c('Female','Male')) +
  ylab("Recovery") +
  theme(legend.position = "none")

race_plot_sec = dat_2 %>%
  ggplot(aes(x = race, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) + 
  scale_x_discrete(labels = c('White','Asian','Black', 'Hispanic')) +
  ylab("Recovery") +
  theme(legend.position = "none")

smoking_plot_sec = dat_2 %>%
  ggplot(aes(x = smoking, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('Never smoked','Former smoker','Current smoker')) +
  ylab("Recovery") +
  theme(legend.position = "none")

hyper_plot_sec = dat_2 %>%
  ggplot(aes(x = hypertension, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) +
  ylab("Recovery") +
  scale_x_discrete(labels = c('No','Yes')) +
  theme(legend.position = "none")

diabetes_plot_sec = dat_2 %>%
  ggplot(aes(x = diabetes, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('No','Yes')) +
  ylab("Recovery") +
  theme(legend.position = "none")

vac_plot_sec = dat_2 %>%
  ggplot(aes(x = vaccine, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('Not vaccinated','Vaccinated')) +
  ylab("Recovery") +
  theme(legend.position = "none")

severity_plot_sec = dat_2 %>%
  ggplot(aes(x = severity, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) +
  scale_x_discrete(labels = c('Not severe','Severe')) + 
  ylab("Recovery") +
  theme(legend.position = "none")

study_plot_sec = dat_2 %>%
  ggplot(aes(x = study, fill = recovery_time)) + 
  geom_bar(color = "black", alpha = .5) +
  ylab("Recovery") +
  theme(legend.position = "none")

(gender_plot_sec + race_plot_sec + smoking_plot_sec + hyper_plot_sec) / (diabetes_plot_sec + vac_plot_sec + severity_plot_sec + study_plot_sec) + 
  plot_layout(guides = "collect") + 
  plot_annotation(title = "Figure 1.5. Bar Plots for Categorical Variables in Secondary Analysis")
```

Note: Red is recovery time less than and equal to 30. Blue is greater than 30. 

ctrl and parallel computing setup:

```{r}
ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 5)
ctrl1 = trainControl(method = "repeatedcv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
no_cores = detectCores() - 1
```

# Primary Analysis

Recovery time as continuous variable. 

## Linear methods: 

### Linear model:

```{r}
set.seed(3521)
# Fit a linear regression model:
lm = train(recovery_time ~ age + gender + race + smoking + height + 
                        weight + bmi + hypertension + diabetes + SBP + 
                        LDL + vaccine + severity + study, 
               data = training, ## use training dataset
               method = "lm", 
               trControl = ctrl)
summary(lm)
# Importances: 
plot(varImp(lm, scale = TRUE), main = "Figure 2. Linear Model Variable's Importance Plot")

# Report the CV error:
lm$results$RMSE
```

[Describe the outputs above]

### LASSO model:

```{r}
set.seed(3521)
# Fit a LASSO model:
lasso = train(x = x, 
              y = y, ## training dataset
              method = "glmnet",
              tuneGrid = expand.grid(alpha = 1,
                                     lambda = exp(seq(-8, 1, length = 100))),
              trControl = ctrl)
# Plot for tuning parameter selection:
plot(lasso, xTrans = log, main = "Figure 3. LASSO Model CV RMSE Plot", highlight = T)
# Choose best tuning parameter value:
lasso$bestTune
# Report the coefficients after applying the best tuning parameter:
coef(lasso$finalModel, lasso$bestTune$lambda)

# Report the CV error:
lasso$results[37, ]$RMSE
```

[Describe the outputs above]

### Ridge model:

```{r}
set.seed(3521)
# Fit a ridge model:
ridge = train(x = x, 
              y = y, ## training dataset
              method = "glmnet",
              tuneGrid = expand.grid(alpha = 0,
                                     lambda = exp(seq(-4, 1, length = 100))),
              trControl = ctrl)
# Plot for tuning parameter selection:
plot(ridge, xTrans = log, main = "Figure 4. Ridge Model CV RMSE Plot", highlight = T)
# Choose best tuning parameter value:
ridge$bestTune
# Report the coefficients after applying the best tuning parameter:
coef(ridge$finalModel, ridge$bestTune$lambda)

# Report the CV error:
ridge$results[73, ]$RMSE
```

[Describe the outputs above]

### Elastic net model:

```{r}
set.seed(3521)
# Fit a Elastic net model:
enet = train(x, y, ## training dataset
             method = "glmnet",
             tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                    lambda = exp(seq(-8, -2, length = 50))),
             trControl = ctrl)
# Plot for tuning parameters selection:
myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
             superpose.line = list(col = myCol))
plot(enet, par.settings = myPar, main = "Figure 5. Elastic Net Model CV RMSE Plot", xTrans = log)
# Choose best tuning parameter value:
enet$bestTune
# Report the coefficients after applying the best tuning parameter:
coef(enet$finalModel, enet$bestTune$lambda)

# Report the CV error:
enet$results[220, ]$RMSE
```

[Describe the outputs above]

### Partial least squares model (PLS): 

```{r}
set.seed(3521)
# Fit a PLS model:
pls = train(x, y,  ## training dataset
            method = "pls",
            tuneGrid = data.frame(ncomp = 1:18),
            trControl = ctrl,
            preProcess = c("center", "scale"))
summary(pls)
# Choose best tuning parameter value:
pls$bestTune
# Plot for the number of components:
ggplot(pls, highlight = T) + 
  theme_bw() +
  ggtitle("Figure 6. PLS Model CV RMSE Plot")

# Report the CV error:
pls$results[11, ]$RMSE
```

[Describe the outputs above]

## Nonlinear Methods: 

### Generalized additive model (GAM): 

```{r}
set.seed(3521)
# Fit a GAM model for all predictors:
gam = train(x, y, ## training dataset
            method = "gam",
            trControl = ctrl)
summary(gam)
# Report the model:
gam$bestTune
gam$finalModel
# Plot for tuning parameter selection:
plot(gam, main = "Figure 7. GAM Model CV RMSE Plot")

# Report the CV error:
gam$results$RMSE
```

[Describe the outputs above]

### Multivariate adaptive regression spline (MARS) model:

```{r}
set.seed(3521)
# Create grid for two tuning parameters in MARS
mars_grid = expand.grid(degree = 1:3,  ## number of possible product hinge functions
                         nprune = 1:20) ##  the number of basis functions to be retained after the pruning process
# Fit the MARS model:
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
mars = train(x, y, # training dataset
              method = "earth",
              tuneGrid = mars_grid,
              trControl = ctrl)
stopCluster(cl)
registerDoSEQ()

# Report the coefficients:
coef(mars$finalModel)
# Plot for tuning parameter selection:
ggplot(mars, highlight = T) + 
  theme_bw() +
  ggtitle("Figure 8. MARS Model CV RMSE Plot")
# Choose best tuning parameter value:
mars$bestTune

# Report the CV error:
mars$results[27, ]$RMSE
```

[Describe the outputs above]

### Regression Tree: 

```{r}
set.seed(3521)
# Fit the regression tree model:
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
reg_tree = train(x, y, ## training dataset
                 method = "rpart",
                 tuneGrid = data.frame(cp = exp(seq(-6, -2, length = 50))),
                 trControl = ctrl)
stopCluster(cl)
registerDoSEQ()
# Plot the regression tree:
rpart.plot(reg_tree$finalModel, main = "Figure 9.1. Regression Tree")
# Plot for tuning parameter selection:
ggplot(reg_tree, highlight = TRUE) + ggtitle("Figure 9.2 Regression Tree Model CV RMSE Plot")
# Choose best tuning parameter value:
reg_tree$bestTune

# Report the CV error:
reg_tree$results[12, ]$RMSE
```

[Describe the outputs above]

### Random Forests: 

```{r}
set.seed(3521)
# Fit the random forest model:
rf.grid = expand.grid(mtry = 1:14, ## We have 14 predictors in training data in total
                      splitrule = "variance",
                      min.node.size = 1:6) ## large/small model flexibility
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
rf = train(x, y,
           method = "ranger",
           tuneGrid = rf.grid,
           trControl = ctrl)
stopCluster(cl)
registerDoSEQ()
# Plot for tuning parameter selection:
ggplot(rf, highlight = TRUE) + ggtitle("Figure 10. Random Forests CV RMSE Plot")
# Choose best tuning parameter value:
rf$bestTune

# Report the CV error:
rf$results[42, ]$RMSE
```

[Describe the outputs above]

### Boosting: 

```{r}
set.seed(3521)
boosting.grid = expand.grid(n.trees = c(2000, 3000, 4000, 5000),
                       interaction.depth = 1:3,
                       shrinkage = c(0.001, 0.003, 0.005),
                       n.minobsinnode = 1)
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
boosting = train(x, y,
                method = "gbm",
                tuneGrid = boosting.grid,
                trControl = ctrl,
                verbose = FALSE)
stopCluster(cl)
registerDoSEQ()

# Plot for tuning parameter selection:
ggplot(boosting, highlight = TRUE) + ggtitle("Figure 11. Boosting CV RMSE Plot")
# Choose best tuning parameter value:
boosting$bestTune

# Report the CV error:
boosting$results[26, ]$RMSE
```

[Describe the outputs above]







# Secondary Analysis

### Logistic Model: 

```{r}
set.seed(3521)
glm = train(recovery_time ~ ., 
            data = training_sec,
            method = "glm", 
            metric = "ROC", 
            trControl = ctrl1)
glm$finalModel

# Report the CV ROC:
glm$results$ROC
# Report the training error rate: 
glm.train = predict(glm, newdata = training_sec)
glm_error = 1 - sum(y_sec == glm.train)/length(y_sec)
sprintf("The training error rate for logistic model is %.3f", glm_error)
```

[Describe the outputs above]

### Penalized Logistic Model: 

```{r}
set.seed(3521)
glmnGrid = expand.grid(alpha = seq(0, 1, length = 18), 
                       lambda = exp(seq(-15, -5, length = 50)))

glmn = train(recovery_time ~ ., 
             data = training_sec,
             method = "glmnet", 
             tuneGrid = glmnGrid, 
             metric = "ROC",
             trControl = ctrl1)
# Plot for tuning parameter selection:
myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
        superpose.line = list(col = myCol))
plot(glmn, par.settings = myPar, xTran = function(x)log(x), highlight = T, main = "Figure I. Penalized Logistic Model CV ROC Plot")
# Choose best tuning parameter value:
glmn$bestTune

# Report the CV ROC:
glmn$results[851, ]$ROC
# Report the training error rate: 
glmn.train = predict(glmn, newdata = training_sec)
glmn_error = 1 - sum(y_sec == glmn.train)/length(y_sec)
sprintf("The training error rate for penalized logistic model is %.3f", glmn_error)
```

[Describe the outputs above]

### GAM model for binary response:

```{r}
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
gam_2 = train(recovery_time ~ ., 
              data = training_sec,
              method = "gam", 
              metric = "ROC", 
              trControl = ctrl1)
stopCluster(cl)
registerDoSEQ()
# Plot for tuning parameter selection:
plot(gam_2, main = "Figure II. GAM Model CV ROC Plot")
# Report the final model: 
gam_2$bestTune
coef(gam_2$finalModel)

# Report the CV ROC:
gam_2$results[2, ]$ROC
# Report the training error rate: 
gam_2.train = predict(gam_2, newdata = training_sec)
gam_2_error = 1 - sum(y_sec == gam_2.train)/length(y_sec)
sprintf("The training error rate for GAM model is %.3f", gam_2_error)
```

[Describe the outputs above]

### MARS model for binary response: 

```{r}
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
mars_2 = train(recovery_time ~ ., 
               data = training_sec,
               method = "earth", 
               tuneGrid = expand.grid(degree = 1:4, nprune = 2:14),
               metric = "ROC", 
               trControl = ctrl1)
stopCluster(cl)
registerDoSEQ()
# Plot for tuning parameter selection:
plot(mars_2, main = "Figure III. MARS Model CV ROC Plot", highlight = T)
# Report the final model:
mars_2$bestTune
coef(mars_2$finalModel)

# Report the CV ROC:
mars_2$results[37, ]$ROC
# Report the training error rate: 
mars_2.train = predict(mars_2, newdata = training_sec)
mars_2_error = 1 - sum(y_sec == mars_2.train)/length(y_sec)
sprintf("The training error rate for MARS model is %.3f", mars_2_error)
```

[Describe the outputs above]

### Linear discriminant analysis (LDA):

```{r}
set.seed(3521)
lda = train(recovery_time ~ ., 
            data = training_sec,
            method = "lda",
            metric = "ROC",
            trControl = ctrl1)
# Report the final model:
coef(lda$finalModel)

# Report the CV ROC:
lda$results$ROC
# Report the training error rate: 
lda.train = predict(lda, newdata = training_sec)
lda_error = 1 - sum(y_sec == lda.train)/length(y_sec)
sprintf("The training error rate for LDA is %.3f", lda_error)
```

[Describe the outputs above]

### Quadratic discriminant analysis (QDA):

```{r}
set.seed(3521)
qda = train(recovery_time ~ ., 
            data = training_sec,
            method = "qda",
            metric = "ROC",
            trControl = ctrl1)
# Report the final model:
qda$finalModel

# Report the CV ROC:
qda$results$ROC
# Report the training error rate: 
qda.train = predict(qda, newdata = training_sec)
qda_error = 1 - sum(y_sec == qda.train)/length(y_sec)
sprintf("The training error rate for QDA model is %.3f", qda_error)
```

[Describe the outputs above]

### Naive Bayes: 

```{r}
set.seed(3521)
nbGrid = expand.grid(usekernel = c(FALSE, TRUE),
                     fL = 1,
                     adjust = seq(.2, 3, by = .2))
nb = train(recovery_time ~ ., 
           data = training_sec, 
           method = "nb",
           tuneGrid = nbGrid,
           metric = "ROC",
           trControl = ctrl1)
# Plot for tuning parameter selection:
plot(nb, main = "Figure IV. NB Model CV ROC Plot", highlight = T)
# Report the final model:
nb$bestTune

# Report the CV ROC:
nb$results[26, ]$ROC
# Report the training error rate: 
nb.train = predict(nb, newdata = training_sec)
nb_error = 1 - sum(y_sec == nb.train)/length(y_sec)
sprintf("The training error rate for Naive Bayes is %.3f", nb_error)
```

[Describe the outputs above]

### Classfication tree: 

```{r}
set.seed(3521)
rpart = train(recovery_time ~ . ,
              data = training_sec,
              method = "rpart",
              tuneGrid = data.frame(cp = exp(seq(-6, -2, length = 50))),
              trControl = ctrl1,
              metric = "ROC")
# Plot for classification tree: 
rpart.plot(rpart$finalModel, main = "Figure V(I). Classification Tree")
# Plot for tuning parameter selection: 
ggplot(rpart, highlight = TRUE) + ggtitle("Figure V(II). Classification Tree Model CV ROC Plot")
# Choose best tuning parameter value:
rpart$bestTune

# Report the CV ROC
rpart$results[17, ]$ROC
# Report the training error rate: 
rpart.train = predict(rpart, newdata = training_sec)
rpart_error = 1 - sum(y_sec == rpart.train)/length(y_sec)
sprintf("The training error rate for classfication tree is %.3f", rpart_error)
```

[Describe the outputs above]

### Conditional Inference Tree: 

```{r}
set.seed(3521)
ctree = train(recovery_time ~ . ,
                  data = training_sec,
                  method = "ctree",
                  tuneGrid = data.frame(mincriterion = 1 - exp(seq(-2, -1, length = 50))),
                  trControl = ctrl1,
                  metric = "ROC")
# Plot for CIT: 
plot(ctree$finalModel, main = ("Figure VI(I). Conditional Inference Tree"))
# Plot for tuning parameter selection: 
ggplot(ctree, highlight = T) + ggtitle("Figure VI(II). CIT Model CV ROC Plot")
# Choose best tuning parameter value:
ctree$bestTune

# Report the CV ROC
ctree$results[20, ]$ROC
# Report the training error rate: 
ctree.train = predict(ctree, newdata = training_sec)
ctree_error = 1 - sum(y_sec == ctree.train)/length(y_sec)
sprintf("The training error rate for conditional inference tree is %.3f", ctree_error)
```

[Describe the outputs above]

### Random Forests for binary response: 

```{r}
rf.grid = expand.grid(mtry = 0:6,
                      splitrule = "gini",
                      min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
rf_2 = train(recovery_time ~ . ,
             data = training_sec,
             method = "ranger",
             tuneGrid = rf.grid,
             trControl = ctrl1,
             metric = "ROC")
stopCluster(cl)
registerDoSEQ()

# Plot for tuning parameter selection: 
ggplot(rf_2, highlight = TRUE) + ggtitle("Figure VII. Random Forests Model CV ROC Plot")
# Choose best tuning parameter value:
rf_2$bestTune

# Report the CV ROC
rf_2$results[6,]$ROC
# Report the training error rate: 
rf_2.train = predict(rf_2, newdata = training_sec)
rf_2_error = 1 - sum(y_sec == rf_2.train)/length(y_sec)
sprintf("The training error rate for random forests is %.3f", rf_2_error)
```

[Describe the outputs above]

### Adaboost Model: 

```{r}
gbmA.grid = expand.grid(n.trees = c(1000, 2000, 3000, 4000),
                        interaction.depth = 1:6,
                        shrinkage = c(0.0005, 0.001, 0.0015),
                        n.minobsinnode = 1)
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
Adaboost = train(recovery_time ~ . ,
                 data = training_sec,
                 tuneGrid = gbmA.grid,
                 trControl = ctrl1,
                 method = "gbm",
                 distribution = "adaboost",
                 metric = "ROC",
                 verbose = FALSE)
stopCluster(cl)
registerDoSEQ()

# Plot for tuning parameter selection:
ggplot(Adaboost, highlight = TRUE) + ggtitle("Figure VIII. Adaboost Model CV ROC Plot")
# Choose best tuning parameter value:
Adaboost$bestTune

# Report the CV ROC:
Adaboost$results[44,]$ROC
# Report the training error rate: 
Adaboost.train = predict(Adaboost, newdata = training_sec)
Adaboost_error = 1 - sum(y_sec == Adaboost.train)/length(y_sec)
sprintf("The training error rate for Adaboost is %.3f", Adaboost_error)
```

[Describe the outputs above]

### Support Vector Machine (linear kernel): 

```{r}
set.seed(3521)
# kernlab 
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
svml = train(recovery_time ~ . ,
             training_sec,
             method = "svmLinear",
             tuneGrid = data.frame(C = exp(seq(-5, 2, len = 50))),
             trControl = ctrl1)
stopCluster(cl)
registerDoSEQ()
# Plot for tuning parameter selection:
plot(svml, highlight = TRUE, xTrans = log, main = ("Figure IX. SVM(linear) Model CV ROC Plot"))
# Choose best tuning parameter value:
svml$bestTune

# Report the CV ROC: 
svml$results[22, ]$ROC
# Report the training error rate: 
svml.train = predict(svml, newdata = training_sec)
svml_error = 1 - sum(y_sec == svml.train)/length(y_sec)
sprintf("The training error rate for SVM(linear) is %.3f", svml_error)
```

[Describe the outputs above]

### Support Vector Machine (radical kernel): 

```{r}
set.seed(3521)
cl = makePSOCKcluster(no_cores)
registerDoParallel(cl)
svmr = train(recovery_time ~ . ,
             training_sec,
             method = "svmRadialCost",
             tuneGrid = data.frame(C = exp(seq(-6, 0, len = 200))),
             trControl = ctrl1)
stopCluster(cl)
registerDoSEQ()
# Plot for tuning parameter selection:
myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
             superpose.line = list(col = myCol))
plot(svmr, highlight = TRUE, par.settings = myPar, main = "Figure X. SVM(radical) Model CV ROC Plot")
# Choose best tuning parameter value:
svmr$bestTune
# Report the CV ROC
svmr$results[85,]$ROC
# Report the training error rate: 
svmr.train = predict(svmr, newdata = training_sec)
svmr_error = 1 - sum(y_sec == svmr.train)/length(y_sec)
sprintf("The training error rate for SVM(radical) is %.3f", svmr_error)
```

[Describe the outputs above]





# Results: 

## Model Comparison: 

### For Primary Analysis: 

```{r}
set.seed(3521)
# Resample all of the methods in primary analysis:
resamp1 = resamples(list(
  "Linear_model" = lm,
  "LASSO" = lasso,
  "Ridge" = ridge,
  "Elastic_net" = enet,
  "PLS" = pls,
  "GAM" = gam,
  "MARS" = mars,
  "Regression_tree" = reg_tree,
  "Random_forests" = rf,
  "Boosting" = boosting
  ))
summary(resamp1)
# RMSE plots for all models:
bwplot(resamp1, 
       metric = "RMSE",
       main = "Figure 12. Primary Analysis: Model Comparison Plot Using RMSE")
```

### For Secondary Analysis: 

```{r}
set.seed(3521)
# Resample all of the methods in secondary analysis:
resamp2 = resamples(list(
  "Logistic_model" = glm,
  "Penalized_logistic_model" = glmn,
  "GAM_binary" = gam_2,
  "Mars_binary" = mars_2,
  "LDA" = lda,
  "QDA" = qda,
  "Naive_bayes" = nb,
  "Classification_tree" = rpart,
  "Conditional_inference_tree" = ctree,
  "Random_forest_binary" = rf_2,
  "Adaboost" = Adaboost,
  "SVM_linear" = svml,
  "SVM_radical" = svmr
  ))
summary(resamp2)
# RMSE plots for all models:
bwplot(resamp2, 
       metric = "ROC",
       main = "Figure XI. Secondary Analysis: Model Comparison Plot Using ROC")
```

From the outputs, we choose random forests for primary analysis and GAM model for secondary analysis. 

## Final model interpretation

### Primary analysis: (Random Forests)

Extract the variable importance: 

```{r}
# Permutation: 
set.seed(3521)
rf.per = ranger(recovery_time ~ ., 
                data = training,
                mtry = rf$bestTune[[1]],
                splitrule = "variance",
                min.node.size = rf$bestTune[[3]],
                importance = "permutation",
                scale.permutation.importance = TRUE)
barplot(sort(importance(rf.per), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7, 
        col = colorRampPalette(colors = c("cyan", "blue"))(19),
        main = "Figure 10.1. Variable Importance by OOB permutation")

# Impurity: 
set.seed(3521)
rf.imp = ranger(recovery_time ~ ., 
                data = training,
                mtry = rf$bestTune[[1]],
                splitrule = "variance",
                min.node.size = rf$bestTune[[3]],
                importance = "impurity")
barplot(sort(importance(rf.imp), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7, 
        col = colorRampPalette(colors = c("cyan", "blue"))(19),
        main = "Figure 10.2. Variable Importance by Node Impurities")
```

Partial dependence plots: 

```{r}
p1 = partial(rf, pred.var = "bmi",
     plot = TRUE, rug = TRUE,
     plot.engine = "ggplot")
p2 = partial(rf, pred.var = "weight",
     plot = TRUE, rug = TRUE,
     plot.engine = "ggplot")
p3 = partial(rf, pred.var = "height",
     plot = TRUE, rug = TRUE,
     plot.engine = "ggplot")
p4 = rf %>% 
     partial(pred.var = c("bmi", "weight"), chull = TRUE) %>% 
     autoplot(train = training, rug = TRUE)
p5 = rf %>% 
     partial(pred.var = c("bmi", "height"), chull = TRUE) %>% 
     autoplot(train = training, rug = TRUE)
p6 = rf %>% 
     partial(pred.var = c("height", "weight"), chull = TRUE) %>% 
     autoplot(train = training, rug = TRUE)
grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 3, top = "Figure 10.3. Random Forests' PDPs for Important Variables")

```

Individual conditional expectation curves (ICE): 

```{r}
ice1 = rf %>% 
  partial(pred.var = "bmi",
          grid.resolution = 100, 
          ice = TRUE) %>% 
  autoplot(train = rf, alpha = 0.1) + ggtitle("ICE for BMI (not centered)")
ice2 = rf %>% 
  partial(pred.var = "bmi",
          grid.resolution = 100, 
          ice = TRUE) %>% 
  autoplot(train = rf, alpha = 0.1, center = TRUE) + ggtitle("ICE for BMI (centered)")
ice3 = rf %>% 
  partial(pred.var = "weight",
          grid.resolution = 100, 
          ice = TRUE) %>% 
  autoplot(train = rf, alpha = 0.1) + ggtitle("ICE for Weight (not centered)")
ice4 = rf %>% 
  partial(pred.var = "weight",
          grid.resolution = 100, 
          ice = TRUE) %>% 
  autoplot(train = rf, alpha = 0.1, center = TRUE) + ggtitle("ICE for Weight (centered)")
ice5 = rf %>% 
  partial(pred.var = "height",
          grid.resolution = 100, 
          ice = TRUE) %>% 
  autoplot(train = rf, alpha = 0.1) + ggtitle("ICE for Height (not centered)")
ice6 = rf %>% 
  partial(pred.var = "height",
          grid.resolution = 100, 
          ice = TRUE) %>% 
  autoplot(train = rf, alpha = 0.1, center = TRUE) + ggtitle("ICE for Height (centered)")

grid.arrange(ice1, ice2, ice3, ice4, ice5, ice6, nrow = 3, top = "Figure 10.4. ICE for Importance Variables")
```


### Secondary analysis: (GAM model)

```{r}
gam_2$finalModel
```

```{r}
par(mfrow = c(3, 2))
plot(gam_2$finalModel)
mtext("Figure II(I). GAM Model Spline Term Plots", side = 3, line = -3, outer = TRUE)
```


## Report the training and test performance

### Primary analysis: 

```{r}
# Cross validation error:
rf$results[42, ]$RMSE
# Test error: 
rf_pred = predict(rf, newdata = x2)
rf_mse = sqrt(mean((rf_pred - y2)^2))
rf_mse
```

### Secondary analysis: 

```{r}
# Training error rate:  
gam_2.train = predict(gam_2, newdata = training_sec)
gam_2_error = 1 - sum(y_sec == gam_2.train)/length(y_sec)
gam_2_error
# Test error rate:
gam_2.test = predict(gam_2, newdata = test_sec)
gam_2_error_t = 1 - sum(y2_sec == gam_2.test)/length(y2_sec)
gam_2_error_t
```


# Conclusions: 

[show it in the report]


